{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optosynth\n",
    "\n",
    "... is it _really_ synthetic?! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "notebook_path = os.path.abspath('')\n",
    "sources_path = os.path.abspath(os.path.join(notebook_path, 'sources'))\n",
    "sys.path.insert(0, sources_path)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pprint import pprint\n",
    "\n",
    "from specs import *\n",
    "from optosynth import Optosynth\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "optosynth_data_path = '/home/jupyter/mb-ml-data-disk/Optosynth'\n",
    "output_path = '/home/jupyter/mb-ml-data-disk/Optosynth_output'\n",
    "output_prefix = 'optosynth_first_wave'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Download pre-processed Allen Brain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(optosynth_data_path):\n",
    "#     os.mkdir(optosynth_data_path)\n",
    "# assert os.path.exists(optosynth_data_path)\n",
    "# data_bucket = 'gs://mb_optosynth_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s \"$data_bucket\" \"$optosynth_data_path\"\n",
    "# mkdir -p $2\n",
    "# gsutil -m cp -r $1/* $2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load summary of available sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>sweep_index</th>\n",
       "      <th>stim_amp</th>\n",
       "      <th>n_spikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480116737</td>\n",
       "      <td>0</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>480116737</td>\n",
       "      <td>1</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>480116737</td>\n",
       "      <td>2</td>\n",
       "      <td>-50.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480116737</td>\n",
       "      <td>3</td>\n",
       "      <td>-30.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>480116737</td>\n",
       "      <td>4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cell_id  sweep_index    stim_amp  n_spikes\n",
       "0  480116737            0 -110.000000         0\n",
       "1  480116737            1  -70.000000         0\n",
       "2  480116737            2  -50.000000         0\n",
       "3  480116737            3  -30.000002         0\n",
       "4  480116737            4   10.000000         0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of sweeps\n",
    "ephys_summary_df = pd.read_csv(\n",
    "    os.path.join(optosynth_data_path, 'processed_electrophysiology_summary.csv'), index_col=0)\n",
    "ephys_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optosynth Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly choosing 5 from 446 usable neurons ...\n",
      "Loading morphology and electrophysiology data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6364f50360a2488992f911aa3ac4d1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating the background pattern generator ...\n",
      "Instantiating the camera ...\n",
      "Generating ground truth masks ...\n",
      "Generating synthetic data for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24773424d2a846abb0923f9de51dc988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cd21bf2caa409fb6afc477ce4c82c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__5 ...\n",
      "Saving noisy .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__5 ...\n",
      "Saving clean .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__5 ...\n",
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369379708e954964badbe12d3c4c1783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__10 ...\n",
      "Saving noisy .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__10 ...\n",
      "Saving clean .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__10 ...\n",
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117170a289e04c7b8ceccf7dc6c387d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__50 ...\n",
      "Saving noisy .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__50 ...\n",
      "Saving clean .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__50 ...\n",
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae372e75802149bbbc8f7bba4b4dc295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__200 ...\n",
      "Saving noisy .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__200 ...\n",
      "Saving clean .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__5__200 ...\n",
      "Randomly choosing 20 from 446 usable neurons ...\n",
      "Loading morphology and electrophysiology data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b03555acf324793978f6ca0db250e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating the background pattern generator ...\n",
      "Instantiating the camera ...\n",
      "Generating ground truth masks ...\n",
      "Generating synthetic data for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bca5f6f193541bd9983e2c8317498a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a484e3f06204783bd9c830a9595033a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__5 ...\n",
      "Saving noisy .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__5 ...\n",
      "Saving clean .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__5 ...\n",
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d535b28b34e4562a1c9c82e493822a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__10 ...\n",
      "Saving noisy .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__10 ...\n",
      "Saving clean .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__10 ...\n",
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538ecdd66dae4d03bc2ae5db08bd9f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__50 ...\n",
      "Saving noisy .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__50 ...\n",
      "Saving clean .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__50 ...\n",
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50928aa6acde4bbebcaccab926a88caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__200 ...\n",
      "Saving noisy .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__200 ...\n",
      "Saving clean .avi movie from segment 0 to /home/jupyter/mb-ml-data-disk/Optosynth_output/optosynth_first_wave__0__20__200 ...\n",
      "Randomly choosing 50 from 446 usable neurons ...\n",
      "Loading morphology and electrophysiology data ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39cb91f60284c7d9c67a9a9032a663e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating the background pattern generator ...\n",
      "Instantiating the camera ...\n",
      "Generating ground truth masks ...\n",
      "Generating synthetic data for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ffcf729c184ea1886dfe2472f00bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating clean and noisy camera readout for segment 1 / 1 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1dcf83721c4f21bab3c054a67479f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-31f88c4b2d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 photon_per_fluorophore=float(photon_per_fluorophore))\n\u001b[1;32m     77\u001b[0m             \u001b[0msynth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcam_specs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0msynth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_camera_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# save raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mb-ml-dev-disk/Optosynth/sources/optosynth.py\u001b[0m in \u001b[0;36mgenerate_camera_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_segment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Generating clean and noisy camera readout for segment {i_segment + 1} / {self.n_segments} ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mcamera_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_camera_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_movie_tyx_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_movie_tyx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoisy_movie_tyx_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'noisy_movie_tyx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mb-ml-dev-disk/Optosynth/sources/optosynth.py\u001b[0m in \u001b[0;36m_generate_camera_data\u001b[0;34m(self, i_segment)\u001b[0m\n\u001b[1;32m    259\u001b[0m             (self.n_frames_per_segment, self.opto_specs.height, self.opto_specs.width))\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_frames_per_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m             \u001b[0mcamera_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbg_tyx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mneuron_fluorescence_tyx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0mclean_movie_tyx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_readout_yx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mnoisy_movie_tyx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcamera_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'noisy_readout_yx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mb-ml-dev-disk/Optosynth/sources/camera.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fluorophore_count_yx)\u001b[0m\n\u001b[1;32m     46\u001b[0m         noisy_readout_yx = (\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcam_specs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadout_per_photon\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblurred_photon_rate_yx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcam_specs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_noise_std\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblurred_photon_rate_yx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             self.cam_specs.dc_offset)\n\u001b[1;32m     50\u001b[0m         \u001b[0mnoisy_readout_yx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoisy_readout_yx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_repeat = 5\n",
    "n_neurons_list = [5, 10, 20]\n",
    "photon_per_fluorophore_list = [5, 10, 50, 200]\n",
    "\n",
    "for i_repeat in range(1, n_repeat + 1):\n",
    "\n",
    "    for n_neurons in n_neurons_list:\n",
    "\n",
    "        opto_specs = OptosynthSpecs(\n",
    "            width=512,\n",
    "            height=180,\n",
    "            sampling_rate=500,\n",
    "            duration_per_segment=2.00,\n",
    "            scale_factor=1.00,\n",
    "            n_neurons=n_neurons,\n",
    "            min_neuron_fluorescence_scale_factor=0.1,\n",
    "            max_neuron_fluorescence_scale_factor=1.0,\n",
    "            stim_amp_range_list=[\n",
    "                (25, 50),\n",
    "                (50, 75),\n",
    "                (75, 100),\n",
    "                (100, 125),\n",
    "                (125, 150),\n",
    "                (150, 175),\n",
    "                (175, 200)])\n",
    "\n",
    "        neuron_specs = SyntheticNeuronSpecs(\n",
    "            dendritic_backprop_velocity=1e4,\n",
    "            dendritic_backprop_decay_lengthscale=20,\n",
    "            min_reporter_density=1,\n",
    "            max_reporter_density=10,\n",
    "            reporter_density_var_lengthscale=2,\n",
    "            ephys_lowpass_freq=250)\n",
    "\n",
    "        bg_specs = BackgroundFluorescenceSpecs(\n",
    "            dynamic_n_components=20,\n",
    "            dynamic_x_lengthscale=10,\n",
    "            dynamic_y_lengthscale=100,\n",
    "            dynamic_fluorophore_density_scale=0.5,\n",
    "            dynamic_temporal_frequency=100,\n",
    "            static_x_lengthscale=5,\n",
    "            static_y_lengthscale=5,\n",
    "            static_min_total_fluorophore_density=0.0,\n",
    "            static_max_total_fluorophore_density=0.1)    \n",
    "\n",
    "        v2f_specs = VoltageToFluorescenceSpecs(\n",
    "            beta=0.01,\n",
    "            v1=-100,\n",
    "            f1=0.4,\n",
    "            v2=50,\n",
    "            f2=1.0)\n",
    "\n",
    "        synth = Optosynth(\n",
    "            opto_specs=opto_specs,\n",
    "            neuron_specs=neuron_specs,\n",
    "            bg_specs=bg_specs,\n",
    "            v2f_specs=v2f_specs,\n",
    "            cam_specs=None,\n",
    "            ephys_summary_df=ephys_summary_df,\n",
    "            optosynth_data_path=optosynth_data_path,\n",
    "            device=device,\n",
    "            dtype=dtype)\n",
    "        \n",
    "        # generate!\n",
    "        synth.generate_fluorescence_data()\n",
    "        \n",
    "        for photon_per_fluorophore in photon_per_fluorophore_list:\n",
    "            \n",
    "            # generate clean and noisy camera data\n",
    "            cam_specs = CameraSpecs(\n",
    "                dc_offset=500,\n",
    "                gaussian_noise_std=10.,\n",
    "                psf_lengthscale=0.25,\n",
    "                readout_per_photon=2.2,\n",
    "                photon_per_fluorophore=float(photon_per_fluorophore))\n",
    "            synth.reset_camera(cam_specs)\n",
    "            synth.generate_camera_data()\n",
    "            \n",
    "            # save raw data\n",
    "            full_output_path = os.path.join(\n",
    "                output_path,\n",
    "                f\"{output_prefix}__{i_repeat}__{n_neurons}__{photon_per_fluorophore}\")\n",
    "            \n",
    "            synth.save(full_output_path)\n",
    "            \n",
    "            # save avi demo\n",
    "            for movie_type in {'clean', 'noisy'}:\n",
    "                synth.generate_avi_from_segment(\n",
    "                    segment_index=(synth.n_segments - 1),\n",
    "                    movie_type=movie_type,\n",
    "                    output_root=full_output_path,\n",
    "                    n_frame_mean_subtraction=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
